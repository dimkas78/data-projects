# Getting Started with Airbyte and Data Ingestion

## Objective

We will try to deploy Airbyte locally and will understand key use cases in the Data Warehouse context. 

## Key Terms

**Airbyte** is an open-source platform designed to streamline data integration tasks. It allows you to extract data from various sources, transform it into a suitable format, and load it into your preferred destinations, such as databases, data warehouses, or cloud storage.

## Prerequisites

- Docker Knowledge
- Understanding of ETL vs ELT

## Implementation

1. [Quickstart Local](https://docs.airbyte.com/using-airbyte/getting-started/oss-quickstart)
2. [Helm values charts](https://artifacthub.io/packages/helm/airbyte/airbyte)

## Materials

- [Getting Started with Airbyte: An Introductory Tutorial for Beginners](https://blog.det.life/getting-started-with-airbyte-an-introductory-tutorial-for-beginners-58887bc3b4dd)
- [Deprecation of Docker Compose in Airbyte 1.0 release and performance issues with abctl](https://discuss.airbyte.io/t/deprecation-of-docker-compose-in-airbyte-1-0-release-and-performance-issues-with-abctl/7984)


All discussions and weekly meetings will be in the Discord channel - **data-engineering-projects**.





